<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Interview Prep</title><link href="http://web-pages.github.io/notes/" rel="alternate"></link><link href="http://web-pages.github.io/notes/feeds/theoretical.atom.xml" rel="self"></link><id>http://web-pages.github.io/notes/</id><updated>2016-02-03T00:00:00-08:00</updated><entry><title>Big O Notation</title><link href="http://web-pages.github.io/notes/theoretical/big-o-notation.html" rel="alternate"></link><updated>2016-02-03T00:00:00-08:00</updated><author><name>Barry Steyn</name></author><id>tag:web-pages.github.io,2016-02-03:notes/theoretical/big-o-notation.html</id><summary type="html">&lt;p&gt;&lt;/p&gt;&lt;div class="videobox"&gt;
&lt;iframe src="https://www.youtube.com/embed/eNsKNfFUqFo" height="390" mozallowfullscreen="" width="640" frameborder="0" allowfullscreen="" webkitallowfullscreen=""&gt;
&lt;/iframe&gt;
&lt;/div&gt;&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Big O notation concerns functions &lt;strong&gt;defined on the positive integers&lt;/strong&gt;:
&lt;/p&gt;
&lt;div class="math"&gt;$$
T(n) = \text{function on }n=1,2,3,\ldots
$$&lt;/div&gt;
&lt;div class="admonition border-box"&gt;
&lt;p class="admonition-title"&gt;English Definition&lt;/p&gt;
&lt;p&gt;A function &lt;span class="math"&gt;\(T(n)\)&lt;/span&gt; is said to be &lt;em&gt;big O&lt;/em&gt; of &lt;span class="math"&gt;\(f(n)\)&lt;/span&gt; if eventually,
(&lt;em&gt;for all sufficiently large values of &lt;span class="math"&gt;\(n\)&lt;/span&gt;&lt;/em&gt;), &lt;span class="math"&gt;\(T(n)\)&lt;/span&gt; is bounded above
by a &lt;em&gt;constant multiple&lt;/em&gt; of &lt;span class="math"&gt;\(f(n)\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id="mathematical-definition"&gt;Mathematical Definition&lt;a href="#mathematical-definition" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;div class="math"&gt;$$
T(n) = O(f(n)) \iff \exists \text{ constants } c, n_0 \text { s.t. } T(n) \leq c\cdot f(n)\hspace{2mm} \forall n \geq n_0
$$&lt;/div&gt;
&lt;h1 id="orders-of-common-functions"&gt;Orders Of Common functions&lt;a href="#orders-of-common-functions" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;This taken from the &lt;a href="https://en.wikipedia.org/wiki/Big_O_notation#Orders_of_common_functions"&gt;wikipedia article&lt;/a&gt;&lt;sup class="print"&gt;L1&lt;/sup&gt;
about Big O.&lt;/p&gt;
&lt;p&gt;The following list is in ascending order of growth:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;span class="math"&gt;\(O(1)\)&lt;/span&gt; - &lt;strong&gt;constant&lt;/strong&gt; - array lookup by index&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(O(\log\log n)\)&lt;/span&gt; - &lt;strong&gt;double logarithmic&lt;/strong&gt; - interpolation search&lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(O(\log n)\)&lt;/span&gt; - logarithm - &lt;a href="../binary-search.html"&gt;Binary Search&lt;/a&gt;&lt;sup class="print"&gt;L2&lt;/sup&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "true";

    if (true) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: '[math]'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;&lt;h2 class="print"&gt;Links&lt;/h2&gt;&lt;div style="margin-left: 2.0em;" class="print"&gt;&lt;ol class="print-links"&gt;&lt;li&gt;https://en.wikipedia.org/wiki/Big_O_notation#Orders_of_common_functions&lt;/li&gt;&lt;li&gt;../binary-search.html&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</summary></entry><entry><title>Imperative Vs Declarative</title><link href="http://web-pages.github.io/notes/theoretical/imperative-vs-declarative.html" rel="alternate"></link><updated>2015-04-05T00:00:00-07:00</updated><author><name>Barry Steyn</name></author><id>tag:web-pages.github.io,2015-04-05:notes/theoretical/imperative-vs-declarative.html</id><summary type="html">&lt;h1 id="definitions"&gt;Definitions&lt;a href="#definitions" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id="imperative"&gt;Imperative&lt;a href="#imperative" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Imperative programming&lt;/em&gt;: tells the “machine” how to do something, 
and as a result what you want to happen will happen.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Imperative programming is a paradigm that &lt;span class="pelican-inline"&gt;describes computation in terms
of statements that change a program state&lt;/span&gt;. In much the same way that the
&lt;a href="http://en.wikipedia.org/wiki/Imperative_mood"&gt;imperative mood&lt;/a&gt;&lt;sup class="print"&gt;L1&lt;/sup&gt; in natural
languages&lt;sup id="sf-imperative-vs-declarative-1-back"&gt;&lt;a href="#sf-imperative-vs-declarative-1" title="A natural language (or ordinary language) is any language which arises, unpremeditated, in the brains of human beings. These are the  languages humans use to communicate. They are distinguished from constructed  and formal languages such as those used to program computers or to study logic" class="simple-footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; expresses commands to take action, imperative programs define
sequences of commands for the computer to perform. &lt;span class="pelican-inline"&gt; In general, Imperative
programming is focused on describing &lt;strong&gt;how&lt;/strong&gt; a program operates&lt;/span&gt;.&lt;/p&gt;
&lt;h3 id="procedural-programming"&gt;Procedural Programming&lt;a href="#procedural-programming" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A procedural paradigm means a program is built from one or more procedures
(also known as subroutines or functions). The idea is that state changes are
localized to procedures or restricted to explicit arguments and returns from
procedures (this is known as [structured programming](http://en.wikipedia.org/wiki/Structured_programming.
Structured programming is normally promoted to improve the maintainability
and overall quality of imperative programs.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Object-oriented_programming"&gt;Object Oriented Programming&lt;/a&gt;&lt;sup class="print"&gt;L2&lt;/sup&gt;
is just an extension of the structured pogramming paradigm.&lt;/p&gt;
&lt;h3 id="disadvantages-of-imperative-programming"&gt;Disadvantages Of Imperative Programming&lt;a href="#disadvantages-of-imperative-programming" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;h2 id="declarative"&gt;Declarative&lt;a href="#declarative" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Declarative programming&lt;/em&gt;: tells the “machine” what you would like 
to happen, and lets the machine figure out how to do it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Declarative programs are often described as a program that is not imperative,
although a number of common definitions do exist:&lt;/p&gt;
&lt;div class="admonition border-box"&gt;
&lt;p class="admonition-title"&gt;Declarative Programming Definitions&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A program that describes what computation should be performed and not how to compute it&lt;/li&gt;
&lt;li&gt;Any programming language that lacks &lt;a href="http://en.wikipedia.org/wiki/Side_effect_(computer_science)"&gt;side effects&lt;/a&gt;&lt;sup class="print"&gt;L3&lt;/sup&gt; (or more specifically, is &lt;a href="http://en.wikipedia.org/wiki/Referential_transparency_(computer_science)"&gt;referentially transparent&lt;/a&gt;&lt;sup class="print"&gt;L4&lt;/sup&gt;)&lt;/li&gt;
&lt;li&gt;A language with a clear correspondence to mathematical logic.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;h1 id="programming-examples"&gt;Programming Examples&lt;a href="#programming-examples" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;h1 id="links"&gt;Links&lt;a href="#links" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://latentflip.com/imperative-vs-declarative/"&gt;Imperative Vs Declarative&lt;/a&gt;&lt;sup class="print"&gt;L5&lt;/sup&gt; - Blog post with some nice examples&lt;/li&gt;
&lt;/ul&gt;&lt;h2 class="print"&gt;Links&lt;/h2&gt;&lt;div style="margin-left: 2.0em;" class="print"&gt;&lt;ol class="print-links"&gt;&lt;li&gt;http://en.wikipedia.org/wiki/Imperative_mood&lt;/li&gt;&lt;li&gt;http://en.wikipedia.org/wiki/Object-oriented_programming&lt;/li&gt;&lt;li&gt;http://en.wikipedia.org/wiki/Side_effect_(computer_science)&lt;/li&gt;&lt;li&gt;http://en.wikipedia.org/wiki/Referential_transparency_(computer_science)&lt;/li&gt;&lt;li&gt;http://latentflip.com/imperative-vs-declarative/&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;ol class="simple-footnotes"&gt;&lt;li id="sf-imperative-vs-declarative-1"&gt;A natural language (or ordinary language) is any language
which arises, unpremeditated, in the brains of human beings. These are the 
languages humans use to communicate. They are distinguished from constructed 
and formal languages such as those used to program computers or to study
logic &lt;a href="#sf-imperative-vs-declarative-1-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</summary><category term="compiler"></category><category term="computer science"></category></entry><entry><title>Machine Learning Week 1</title><link href="http://web-pages.github.io/notes/theoretical/machine-learning-week-1.html" rel="alternate"></link><updated>2015-04-05T00:00:00-07:00</updated><author><name>Barry Steyn</name></author><id>tag:web-pages.github.io,2015-04-05:notes/theoretical/machine-learning-week-1.html</id><summary type="html">&lt;h1 id="week-1"&gt;Week 1&lt;a class="headerlink" href="#week-1" title="Permanent link"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;There are several types of machine learning algorithms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Supervised&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Unsupervised&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reinforcement Learning&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recommender Systems&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="supervised-learning-introduction"&gt;Supervised Learning Introduction&lt;a class="headerlink" href="#supervised-learning-introduction" title="Permanent link"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Two common supervised learning outcomes:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Regression - predict a real number output&lt;/li&gt;
&lt;li&gt;Classification - a discrete valued prediction&lt;/li&gt;
&lt;/ol&gt;</summary><category term="machine learning"></category><category term="computer science"></category></entry><entry><title>The Master Method</title><link href="http://web-pages.github.io/notes/theoretical/the-master-method.html" rel="alternate"></link><updated>2013-02-27T00:00:00-08:00</updated><author><name>Barry Steyn</name></author><id>tag:web-pages.github.io,2013-02-27:notes/theoretical/the-master-method.html</id><summary type="html">&lt;p&gt;&lt;/p&gt;&lt;div class="videobox"&gt;
&lt;iframe src="https://www.youtube.com/embed/videoseries?list=PLrr-4051WQe_JqgM-y11Lb5ZUTXvSwa-h" height="390" mozallowfullscreen="" width="640" frameborder="0" allowfullscreen="" webkitallowfullscreen=""&gt;
&lt;/iframe&gt;
&lt;/div&gt;&lt;p&gt;&lt;/p&gt;
&lt;p&gt;The master method is a way to analyse the worst case running times of a recursive function. Assume the recursive function is of the following form:&lt;/p&gt;
&lt;div class="math"&gt;$$ T(n) = a\cdot T\left(\frac{n}{b}\right) + O(n)^d$$&lt;/div&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;a&lt;/strong&gt; is the number of subproblems created. &lt;u&gt;Known as the &lt;em&gt;rate of subproblem proliferation&lt;/em&gt; (RSP).&lt;/u&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;b&lt;/strong&gt; is the constant dividing factor that controls the size of each subproblem's input. &lt;u&gt;Known as the rate of work shrinkage (RWS).&lt;/u&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;d&lt;/strong&gt; is the exponent for the amount of work done on each recursive level.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then&lt;/p&gt;
&lt;div class="math"&gt;$$ T(n) = \begin{cases} O(n^d\cdot log n) &amp;amp; \text{if}\ a = b^d\ \text{case 1} \cr O(n^d) &amp;amp; \text{if}\ a &amp;lt; b^d\ \text{case 2}\cr O(n^{log_ba}) &amp;amp; \text{if}\ a &amp;gt; b^d\ \text{case 3}\end{cases}$$&lt;/div&gt;
&lt;h1 id="canonical-example-merge-sort"&gt;Canonical Example: Merge Sort&lt;a href="#canonical-example-merge-sort" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Merge sort is the classic divide-and-conquer algorithm. It is a comparison based sort that achieves the best time possible for comparison base sorts: &lt;span class="math"&gt;\(O(n\cdot log(n))\)&lt;/span&gt;. For merge sort, the recursive function would be the following:
&lt;/p&gt;
&lt;div class="math"&gt;$$ T(n) = 2\cdot T\left(\frac{n}{2}\right) + O(n)$$&lt;/div&gt;
&lt;p&gt; To spell things out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;a&lt;/strong&gt; is 2. Merge sort divides its input into two, and then recursively works on each sub problem. Therefore there are two sub problems and hence a=2.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;b&lt;/strong&gt; is 2. Each subproblem's input is divided by 2, hence b=2.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;d&lt;/strong&gt; is 1. This is the work done at each level after the recursive calls. For merge sort, the work is merging each of the two &lt;span class="math"&gt;\(\frac{n}{2}\)&lt;/span&gt; input of the subproblem.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is easy to see via a recursion tree that Merge sort takes &lt;span class="math"&gt;\(O(n\cdot logn)\)&lt;/span&gt; time. The master method totally agrees with this, as merge sort falls into case 1, with &lt;span class="math"&gt;\(a=2\)&lt;/span&gt;, &lt;span class="math"&gt;\(b=2\)&lt;/span&gt; and &lt;span class="math"&gt;\(d=1\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1 id="the-work-done-at-each-level"&gt;The Work Done At Each Level&lt;a href="#the-work-done-at-each-level" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;At any level &lt;span class="math"&gt;\(j\)&lt;/span&gt; in the recursive subtree, there are &lt;span class="math"&gt;\(a^j\)&lt;/span&gt; subproblems of size &lt;span class="math"&gt;\(\frac{n}{b^j}\)&lt;/span&gt;. Therefore at any one particular level, the work at level &lt;span class="math"&gt;\(j\)&lt;/span&gt; is:
&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}
\text{Work done at level j} \leq a^j \cdot c\cdot \left( \frac{n}{b^j} \right)^d = c\cdot n^d \left(\frac{a}{b^d}\right)^j \label{wdael}
\end{equation}&lt;/div&gt;
&lt;h1 id="total-work-done"&gt;Total Work Done&lt;a href="#total-work-done" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;At any recursion tree, the leaves are at level &lt;span class="math"&gt;\(log_b(n)\)&lt;/span&gt;, where &lt;em&gt;b&lt;/em&gt; is the rate of work shrinkage. The merge sort canonical example demonstrates this - &lt;em&gt;b&lt;/em&gt; is 2 (problem is halved at each level of the recursion tree), and so there are &lt;span class="math"&gt;\(log_2(n)\)&lt;/span&gt; before the leaves are hit.&lt;/p&gt;
&lt;p&gt;If the work done at each level is dominated by inequality &lt;span class="math"&gt;\(\ref{wdael}\)&lt;/span&gt;, then the total work done is the sum of up to &lt;span class="math"&gt;\(log_b(n)\)&lt;/span&gt;:
&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}
\text{Total work done} \leq c\cdot n^d \sum_{j=0}^{log_bn} \left(\frac{a}{b^d}\right)^j \label{twd}
\end{equation}&lt;/div&gt;
&lt;h2 id="intuition-for-the-three-cases"&gt;Intuition For The Three Cases&lt;a href="#intuition-for-the-three-cases" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;When the master method was first explained to me, my lecturer humorously called the rate of work shrinkage (RWS - denoted by &lt;em&gt;b&lt;/em&gt;) the &lt;em&gt;"force of good"&lt;/em&gt; and the rate of subproblem proliferation (RSP - denoted by &lt;em&gt;a&lt;/em&gt;) the &lt;em&gt;"force of evil"&lt;/em&gt;. The following paragraphs perhaps explain this humour.&lt;/p&gt;
&lt;h3 id="rws-rsp"&gt;RWS = RSP&lt;a href="#rws-rsp" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When rate of work shrinkage is equal to rate of subproblem proliferation, then the same amount of work is being done for each level of the recursion. Therefore work done is calculated by multiplying the number of levels by the work done at every level (Case 1: &lt;span class="math"&gt;\(O(n^d\cdot log(n))\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Again, the canonical merge sort example: There are &lt;span class="math"&gt;\(log_2n\)&lt;/span&gt; levels, with each level doing &lt;span class="math"&gt;\(O(n)\)&lt;/span&gt; work. Therefore total is &lt;span class="math"&gt;\(n\cdot log(n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;h3 id="rws-rsp_1"&gt;RWS &amp;gt; RSP&lt;a href="#rws-rsp_1" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When rate of work shrinkage is greater than rate of subproblem proliferation, then work done is &lt;em&gt;decreasing&lt;/em&gt; at each level (btw: This is very rare but when it happens is very good). Work done will therefore be dominated by the root of the recursion tree (Case 2: &lt;span class="math"&gt;\(O(n^d)\)&lt;/span&gt;).&lt;/p&gt;
&lt;h3 id="rws-rsp_2"&gt;RWS &amp;lt; RSP&lt;a href="#rws-rsp_2" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When rate of work shrinkage is less than rate of subproblem proliferation, work is &lt;em&gt;increasing&lt;/em&gt; at each level of the recursion. Work done will therefore be dominated by the leaves of the recursion tree (Case 3: expect O(#number of leaves)).&lt;/p&gt;
&lt;h1 id="master-method-proof"&gt;Master Method Proof&lt;a href="#master-method-proof" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h1&gt;
&lt;h2 id="lemma"&gt;Lemma&lt;a href="#lemma" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The following lemma will help with the proof.&lt;/p&gt;
&lt;p&gt;For &lt;span class="math"&gt;\(r \neq 1\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$ 1 + r + r^2 + r^3 + \ldots + r^k = \frac{r^{k+1}-1}{r-1}$$&lt;/div&gt;
&lt;p&gt;The above can be proved by induction, and &lt;a href="http://doctrina.org/Mathematical_Nonsense_-Inifinite-Sum-Series.html"&gt;I have done this just&lt;/a&gt;&lt;sup class="print"&gt;L1&lt;/sup&gt; for fun. From the above, two facts follow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(r &amp;lt; 1\)&lt;/span&gt;, then the sum is bounded above by &lt;span class="math"&gt;\(\frac{1}{1-r}\)&lt;/span&gt;. This means that the first term in the sum is the dominant term. Therefore the sum can be bounded above by some constant.&lt;/li&gt;
&lt;li&gt;If &lt;span class="math"&gt;\(r &amp;gt; 1\)&lt;/span&gt;, then the sum is bounded above bt &lt;span class="math"&gt;\(r^k\cdot\left(1 + \frac{1}{1-r} \right)\)&lt;/span&gt;. This means that the last term (i.e. &lt;span class="math"&gt;\(r^k\)&lt;/span&gt;) is the dominant term, and in fact, the sum will always be less then &lt;span class="math"&gt;\(2\cdot r^k\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="proof-for-case-1"&gt;Proof For Case 1&lt;a href="#proof-for-case-1" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Assume &lt;span class="math"&gt;\(a=b^d\)&lt;/span&gt;, then &lt;span class="math"&gt;\(\left(\frac{a}{b^d}\right) = 1\)&lt;/span&gt;, and so &lt;span class="math"&gt;\(\sum_{j=0}^{log_bn} \left(\frac{a}{b^d}\right)^j = log_b(n) + 1\)&lt;/span&gt;. With this in mind: &lt;span class="math"&gt;\(c\cdot n^d \sum_{j=0}^{log_bn} \left(\frac{a}{b^d}\right)^j = c\cdot n^d \cdot log_b(n) + 1 = O(n^d\cdot log n)\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="proof-for-case-2"&gt;Proof For Case 2&lt;a href="#proof-for-case-2" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(a &amp;lt; b^d\)&lt;/span&gt;, then &lt;span class="math"&gt;\(\left(\frac{a}{b^d}\right) &amp;lt; 1\)&lt;/span&gt;. This is where the above lemma comes into play, because &lt;span class="math"&gt;\(\sum_{j=0}^{log_bn} \left(\frac{a}{b^d}\right)^j \leq f\)&lt;/span&gt;. Why do I use the constant &lt;em&gt;f&lt;/em&gt;? It is because in the lemma above, there is a constant that will always be greater than &lt;span class="math"&gt;\(\frac{1}{1-r}\)&lt;/span&gt; if &lt;span class="math"&gt;\(r &amp;lt; 1\)&lt;/span&gt;. Therefore &lt;span class="math"&gt;\(c\cdot n^d \sum_{j=0}^{log_bn} \left(\frac{a}{b^d}\right)^j \leq f\cdot c\cdot n^d = O(n^d)\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id="proof-for-case-3"&gt;Proof For Case 3&lt;a href="#proof-for-case-3" title="Permanent link" class="headerlink"&gt;&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Before I begin the proof for case 3, in a recursion tree, how many leaves are there? The answer: &lt;span class="math"&gt;\(a^{log_bn}\)&lt;/span&gt;. This is because there are &lt;span class="math"&gt;\(log_b(n)\)&lt;/span&gt; levels in the recursion tree, with each level splitting into &lt;em&gt;a&lt;/em&gt; subproblems.&lt;/p&gt;
&lt;p&gt;If &lt;span class="math"&gt;\(a &amp;gt; b^d\)&lt;/span&gt;, then &lt;span class="math"&gt;\(\left(\frac{a}{b^d}\right) &amp;gt; 1\)&lt;/span&gt;. Again, the above lemma comes into play: &lt;span class="math"&gt;\(\sum_{j=0}^{log_bn} \left(\frac{a}{b^d}\right)^j \leq 2\cdot \left(\frac{a}{b^d}\right)^{log_bn}\)&lt;/span&gt;. Therefore &lt;span class="math"&gt;\(c\cdot n^d \sum_{j=0}^{log_bn} \left(\frac{a}{b^d}\right)^j \leq 2\cdot c\cdot n^d \cdot \left(\frac{a}{b^d}\right)^{log_bn}\)&lt;/span&gt;. Note that &lt;span class="math"&gt;\(b^{-dlog_bn} = \left(b^{log_bn}\right)^{-d} = n^{-d}\)&lt;/span&gt;. So &lt;span class="math"&gt;\(2\cdot c\cdot n^d \cdot \left(\frac{a}{b^d}\right)^{log_bn} = 2\cdot c\cdot a^{log_bn} = O(a^{log_bn})\)&lt;/span&gt;. As shown above, this is the number of recursion leaves.&lt;/p&gt;
&lt;p&gt;The more astute of you out there may notice that &lt;em&gt;case 3&lt;/em&gt; was presented as &lt;span class="math"&gt;\(O(n^{log_ba})\)&lt;/span&gt;. This is because &lt;span class="math"&gt;\(n^{log_ba} = a^{log_bn}\)&lt;/span&gt; (I did not believe this at first, and had to &lt;a href="http://doctrina.org/Mathematical_Nonsense_Lemma-For-Logarithm-Equality.html"&gt;prove&lt;/a&gt;&lt;sup class="print"&gt;L2&lt;/sup&gt; it to myself). Even though it is more intuitive to understand &lt;span class="math"&gt;\(a^{log_bn}\)&lt;/span&gt; (i.e. the leaves of the recursion sub tree), it is more consistent with the other cases to calculate &lt;span class="math"&gt;\(n^{log_ba}\)&lt;/span&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "true";

    if (true) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: '[math]'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;&lt;h2 class="print"&gt;Links&lt;/h2&gt;&lt;div style="margin-left: 2.0em;" class="print"&gt;&lt;ol class="print-links"&gt;&lt;li&gt;http://doctrina.org/Mathematical_Nonsense_-Inifinite-Sum-Series.html&lt;/li&gt;&lt;li&gt;http://doctrina.org/Mathematical_Nonsense_Lemma-For-Logarithm-Equality.html&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</summary></entry></feed>